services:
  # nginx 反向代理服务
  nginx:
    image: nginx:alpine
    container_name: nginx_proxy
    ports:
      - "80:80"
      - "443:443"  # 为将来的 SSL 配置预留
    volumes:
      - ./nginx/nginx.dev.conf:/etc/nginx/nginx.conf:ro
      - ./nginx/conf/dev:/etc/nginx/conf.d:ro
      - dev_nginx_logs:/var/log/nginx
    depends_on:
      - frontend
      - backend
    networks:
      - dbNetWork
    healthcheck:
      test: ["CMD", "nginx", "-t"]
      interval: 30s
      timeout: 10s
      retries: 3
    restart: unless-stopped

  frontend:
    build: ./frontend
    env_file:
      - .env.dev
    # 移除端口映射，只通过 nginx 访问
    expose:
      - "3000"
    volumes:
      - ./frontend:/app
      - /app/node_modules
    environment:
      - NODE_ENV=development
    depends_on:
      - backend
    networks:
      - dbNetWork
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:3000"]
      interval: 30s
      timeout: 10s
      retries: 3

  backend:
    image: react-fastapi-postgres-backend:latest
    build:
      context: ./backend
      dockerfile: Dockerfile
    env_file:
      - .env.dev
    # 移除端口映射，只通过 nginx 访问
    expose:
      - "8000"
    volumes:
      - ./backend:/app
      - models_data:/models:ro
    environment:
      - POSTGRES_HOST=${POSTGRES_HOST}
      - POSTGRES_USER=${POSTGRES_USER}
      - POSTGRES_PASSWORD=${POSTGRES_PASSWORD}
      - POSTGRES_DB=${POSTGRES_DB}
      - SECRET_KEY=${SECRET_KEY}
      - ACCESS_TOKEN_EXPIRE_MINUTES=${ACCESS_TOKEN_EXPIRE_MINUTES}
      - RABBITMQ_HOST=${RABBITMQ_HOST}
      - RABBITMQ_USER=${RABBITMQ_USER:-guest}
      - RABBITMQ_PASSWORD=${RABBITMQ_PASSWORD:-guest}
      - REDIS_HOST=${REDIS_HOST}
      - REDIS_PORT=${REDIS_PORT}
      - REDIS_DB=${REDIS_DB}
      - REDIS_PASSWORD=${REDIS_PASSWORD}
      - LLM_BASE_URL=${LLM_BASE_URL}
      - LLM_API_KEY=${LLM_API_KEY}
      - EMBEDDING_MODEL=${EMBEDDING_MODEL}
      - RAG_TOP_K=${RAG_TOP_K:-3}
      - HF_HOME=/models/hf
      - HF_HUB_OFFLINE=1
    depends_on:
      postgres:
        condition: service_healthy
      rabbitmq:
        condition: service_healthy
      redis:
        condition: service_healthy
      llama_server:
        condition: service_healthy
      spacy_init:
        condition: service_completed_successfully
      embeddings_init:
        condition: service_completed_successfully
    command: >
      bash -c "
        URLS=\"$${SPACY_MODEL_URLS:-$${SPACY_MODEL_URL}}\" &&
        echo '安装本地 spaCy 模型...' &&
        for U in $$(echo \"$${URLS}\" | tr ',' ' '); do \
          F=$$(basename \"$${U}\"); \
          echo \" - pip install /models/$${F}\"; \
          poetry run pip install /models/$${F} || true; \
        done &&
        echo '等待数据库准备...' &&
        echo '应用数据库迁移...' &&
        poetry run alembic upgrade head &&
        echo '启动应用服务器...' &&
        poetry run uvicorn app.main:app --host 0.0.0.0 --port 8000 --reload --reload-dir app --reload-exclude '**/.venv/**' --reload-exclude '**/node_modules/**'
      "
    networks:
      - dbNetWork
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s

  postgres:
    image: pgvector/pgvector:pg16
    env_file:
      - .env.dev
    ports:
      - "127.0.0.1:${POSTGRES_PORT}:5432"
    environment:
      - POSTGRES_USER=${POSTGRES_USER}
      - POSTGRES_PASSWORD=${POSTGRES_PASSWORD}
      - POSTGRES_DB=${POSTGRES_DB}
    volumes:
      - dev_postgres_data:/var/lib/postgresql/data
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U ${POSTGRES_USER} -d ${POSTGRES_DB}"]
      interval: 10s
      timeout: 5s
      retries: 5
    networks:
      - dbNetWork

  # 预下载嵌入模型（一次性执行，完成即退出）
  embeddings_init:
    image: python:3.11-slim
    env_file:
      - .env.dev
    environment:
      - EMBEDDING_MODEL=${EMBEDDING_MODEL}
      - HF_TOKEN=${HF_TOKEN}
      - HF_HOME=/models/hf
      - HF_HUB_ENABLE_HF_TRANSFER=1
      - PIP_NO_CACHE_DIR=1
    command: ["sh", "/entry-scripts/embeddings_init.sh"]
    volumes:
      - models_data:/models
      - ./scripts:/entry-scripts:ro
    restart: "no"
    networks:
      - dbNetWork

  pgadmin:
    image: dpage/pgadmin4:9
    env_file:
      - .env.dev
    ports:
      - "127.0.0.1:${PGADMIN_PORT}:80"
    environment:
      - PGADMIN_DEFAULT_EMAIL=${PGADMIN_DEFAULT_EMAIL}
      - PGADMIN_DEFAULT_PASSWORD=${PGADMIN_DEFAULT_PASSWORD}
      - PGADMIN_CONFIG_SERVER_MODE=${PGADMIN_CONFIG_SERVER_MODE}
      - PGADMIN_CONFIG_ENHANCED_COOKIE_PROTECTION=${PGADMIN_CONFIG_ENHANCED_COOKIE_PROTECTION}
      - PGADMIN_CONFIG_WTF_CSRF_ENABLED=${PGADMIN_CONFIG_WTF_CSRF_ENABLED}
    depends_on:
      postgres:
        condition: service_healthy
    networks:
      - dbNetWork
    healthcheck:
      test: ["CMD-SHELL", "python3 -c \"import urllib.request,sys; sys.exit(0 if urllib.request.urlopen('http://localhost/misc/ping').getcode()==200 else 1)\""]
      interval: 30s
      timeout: 10s
      retries: 3

  rabbitmq:
    image: rabbitmq:4-management
    env_file:
      - .env.dev
    expose:
      - "5672"
    ports:
      - "127.0.0.1:${RABBITMQ_PLUGIN_PORT}:15672"
    environment:
      - RABBITMQ_DEFAULT_USER=${RABBITMQ_USER:-guest}
      - RABBITMQ_DEFAULT_PASS=${RABBITMQ_PASSWORD:-guest}
      - RABBITMQ_DEFAULT_VHOST=${RABBITMQ_VHOST:-/}
    volumes:
      - dev_rabbitmq_data:/var/lib/rabbitmq
    healthcheck:
      test: ["CMD", "rabbitmq-diagnostics", "ping"]
      interval: 30s
      timeout: 10s
      retries: 5
    networks:
      - dbNetWork

  redis:
    image: redis:7-alpine
    env_file:
      - .env.dev
    ports:
      - "127.0.0.1:${REDIS_PORT}:6379"
    volumes:
      - dev_redis_data:/data
    command: >
      sh -c "
        if [ -n '${REDIS_PASSWORD}' ]; then
          redis-server --requirepass ${REDIS_PASSWORD}
        else
          redis-server
        fi
      "
    healthcheck:
      test: >
        sh -c "
          if [ -n '${REDIS_PASSWORD}' ]; then
            redis-cli -a ${REDIS_PASSWORD} ping
          else
            redis-cli ping
          fi
        "
      interval: 30s
      timeout: 5s
      retries: 5
    networks:
      - dbNetWork

  # 预下载模型（一次性执行，完成即退出）
  llm_init:
    image: python:3.11-slim
    env_file:
      - .env.dev
    environment:
      - HF_TOKEN=${HF_TOKEN}
      - HF_REPO_ID=${HF_REPO_ID}
      - HF_FILENAME=${HF_FILENAME}
      - HF_REVISION=${HF_REVISION:-main}
      - PIP_NO_CACHE_DIR=1
      - HF_HUB_ENABLE_HF_TRANSFER=1
    command: ["sh", "/entry-scripts/llm_init.sh"]
    volumes:
      - models_data:/models
      - ./scripts:/entry-scripts:ro
    restart: "no"
    networks:
      - dbNetWork

  # 预下载 spaCy 模型（一次性执行，完成即退出）
  spacy_init:
    image: python:3.11-slim
    env_file:
      - .env.dev
    environment:
      - SPACY_MODEL_URLS=${SPACY_MODEL_URLS}
      - PIP_NO_CACHE_DIR=1
      - PIP_DEFAULT_TIMEOUT=1200
    command: ["sh", "/entry-scripts/spacy_init.sh"]
    volumes:
      - models_data:/models
      - ./scripts:/entry-scripts:ro
    restart: "no"
    networks:
      - dbNetWork

  # OpenAI 兼容的 llama.cpp 服务器（内网可见，不对外暴露）
  llama_server:
    image: ghcr.io/ggerganov/llama.cpp:server
    env_file:
      - .env.dev
    depends_on:
      llm_init:
        condition: service_completed_successfully
    healthcheck:
      test: ["CMD-SHELL", "curl -fsS http://127.0.0.1:8080/v1/models >/dev/null || exit 1"]
      interval: 10s
      timeout: 5s
      retries: 6
      start_period: 15s
    command:
      - --model
      - /models/${HF_FILENAME}
      - --port
      - "8080"
      - --host
      - 0.0.0.0
      - --ctx-size
      - "8192"
      - --parallel
      - "2"
      - --api-key
      - ${LLM_API_KEY}
    expose:
      - "8080"
    volumes:
      - models_data:/models:ro
    restart: unless-stopped
    networks:
      - dbNetWork

  taskiq_worker:
    image: react-fastapi-postgres-backend:latest
    env_file:
      - .env.dev
    volumes:
      - ./backend:/app  # 添加卷挂载支持热重载
      - models_data:/models:ro
    environment:
      - POSTGRES_HOST=${POSTGRES_HOST}
      - POSTGRES_USER=${POSTGRES_USER}
      - POSTGRES_PASSWORD=${POSTGRES_PASSWORD}
      - POSTGRES_DB=${POSTGRES_DB}
      - RABBITMQ_HOST=${RABBITMQ_HOST}
      - RABBITMQ_USER=${RABBITMQ_USER:-guest}
      - RABBITMQ_PASSWORD=${RABBITMQ_PASSWORD:-guest}
      - RABBITMQ_DEFAULT_VHOST=${RABBITMQ_VHOST:-/}
      - REDIS_HOST=${REDIS_HOST}
      - REDIS_PORT=${REDIS_PORT}
      - REDIS_DB=${REDIS_DB}
      - REDIS_PASSWORD=${REDIS_PASSWORD}
      - HF_HOME=/models/hf
      - HF_HUB_OFFLINE=1
    depends_on:
      postgres:
        condition: service_healthy
      rabbitmq:
        condition: service_healthy
      redis:
        condition: service_healthy
      embeddings_init:
        condition: service_completed_successfully
    command: >
      bash -c "
        echo '等待依赖服务...' &&
        sleep 10 &&
        poetry run taskiq worker --fs-discover --tasks-pattern 'app/modules/tasks/workers/*.py' app.broker:broker --reload --log-level ${LOG_LEVEL:-INFO}
      "
    scale: ${TASKIQ_WORKER_CONCURRENCY:-2}
    networks:
      - dbNetWork
    healthcheck:
      test: ["CMD", "pgrep", "-f", "taskiq worker"]
      interval: 60s
      timeout: 10s
      retries: 3

  taskiq_scheduler:
    image: react-fastapi-postgres-backend:latest
    env_file:
      - .env.dev
    volumes:
      - ./backend:/app  # 添加卷挂载支持热重载
      - models_data:/models:ro
    environment:
      - POSTGRES_HOST=${POSTGRES_HOST}
      - POSTGRES_USER=${POSTGRES_USER}
      - POSTGRES_PASSWORD=${POSTGRES_PASSWORD}
      - POSTGRES_DB=${POSTGRES_DB}
      - RABBITMQ_HOST=${RABBITMQ_HOST}
      - RABBITMQ_USER=${RABBITMQ_USER:-guest}
      - RABBITMQ_PASSWORD=${RABBITMQ_PASSWORD:-guest}
      - RABBITMQ_DEFAULT_VHOST=${RABBITMQ_VHOST:-/}
      - REDIS_HOST=${REDIS_HOST}
      - REDIS_PORT=${REDIS_PORT}
      - REDIS_DB=${REDIS_DB}
      - REDIS_PASSWORD=${REDIS_PASSWORD}
      - HF_HOME=/models/hf
      - HF_HUB_OFFLINE=1
    depends_on:
      postgres:
        condition: service_healthy
      rabbitmq:
        condition: service_healthy
      redis:
        condition: service_healthy
      taskiq_worker:
        condition: service_started
      embeddings_init:
        condition: service_completed_successfully
    command: >
      bash -c "
        echo '等待依赖服务...' &&
        sleep 15 &&
        poetry run taskiq scheduler app.broker:scheduler --log-level ${LOG_LEVEL:-INFO}
      "
    networks:
      - dbNetWork
    healthcheck:
      test: ["CMD", "pgrep", "-f", "taskiq scheduler"]
      interval: 60s
      timeout: 10s
      retries: 3

  redisinsight:
    image: redislabs/redisinsight:2.70.0
    container_name: redisinsight_dev
    env_file:
      - .env.dev
    ports:
      - "127.0.0.1:${REDISINSIGHT_PORT:-5540}:5540"
    volumes:
      - dev_redisinsight_data:/db
    environment:
      - RITRUSTEDORIGINS=http://localhost:${REDISINSIGHT_PORT:-5540}
    depends_on:
      redis:
        condition: service_healthy
    restart: unless-stopped
    networks:
      - dbNetWork
    healthcheck:
      test: ["CMD-SHELL", "wget -q --spider http://127.0.0.1:5540/healthcheck/ || exit 1"]
      interval: 30s
      timeout: 10s
      retries: 3

  # Portainer 容器管理（仅本机访问）
  portainer:
    image: portainer/portainer-ce:2.27.9-alpine
    container_name: portainer_dev
    env_file:
      - .env.dev
    ports:
      - "127.0.0.1:${PORTAINER_PORT:-9000}:9000"
    volumes:
      - /var/run/docker.sock:/var/run/docker.sock
      - dev_portainer_data:/data
    networks:
      - dbNetWork
    restart: unless-stopped
    healthcheck:
      test: ["CMD-SHELL", "wget -q --spider http://localhost:9000/api/system/status || exit 1"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s

volumes:
  dev_postgres_data:
  dev_rabbitmq_data:
  dev_redis_data:
  dev_redisinsight_data:
  dev_portainer_data:
  dev_nginx_logs:
  models_data:

networks:
  dbNetWork:
    driver: bridge
