services:
  oauth2_proxy:
    image: quay.io/oauth2-proxy/oauth2-proxy:v7.12.0-alpine
    env_file:
      - .env.prod
    environment:
      - OAUTH2_PROXY_PROVIDER=${OAUTH2_PROXY_PROVIDER}
      - OAUTH2_PROXY_CLIENT_ID=${OAUTH2_PROXY_CLIENT_ID}
      - OAUTH2_PROXY_CLIENT_SECRET=${OAUTH2_PROXY_CLIENT_SECRET}
      - OAUTH2_PROXY_COOKIE_SECRET=${OAUTH2_PROXY_COOKIE_SECRET}
      - OAUTH2_PROXY_REVERSE_PROXY=${OAUTH2_PROXY_REVERSE_PROXY:-true}
      - OAUTH2_PROXY_SET_XAUTHREQUEST=${OAUTH2_PROXY_SET_XAUTHREQUEST:-true}
      - OAUTH2_PROXY_HTTP_ADDRESS=${OAUTH2_PROXY_HTTP_ADDRESS:-0.0.0.0:4180}
      - OAUTH2_PROXY_REDIRECT_URL=${OAUTH2_PROXY_REDIRECT_URL:-https://auth.${DOMAIN_MAIN}/oauth2/callback}
      - OAUTH2_PROXY_EMAIL_DOMAINS=${OAUTH2_PROXY_EMAIL_DOMAINS:-*}
      - OAUTH2_PROXY_UPSTREAMS=${OAUTH2_PROXY_UPSTREAMS:-static://200}
      - OAUTH2_PROXY_COOKIE_SECURE=${OAUTH2_PROXY_COOKIE_SECURE:-true}
      # 允许跨子域共享会话并允许跨子域重定向
      - OAUTH2_PROXY_COOKIE_DOMAINS=${OAUTH2_PROXY_COOKIE_DOMAINS:-.${DOMAIN_MAIN}}
      - OAUTH2_PROXY_WHITELIST_DOMAINS=${OAUTH2_PROXY_WHITELIST_DOMAINS:-.${DOMAIN_MAIN}}
    expose:
      - "4180"
    networks:
      - prodNetWork
    restart: unless-stopped
    mem_limit: 128M
    mem_reservation: 64M
    healthcheck:
      test: ["CMD-SHELL", "wget -q --spider http://localhost:4180/ping || exit 1"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 20s

  # nginx 反向代理服务
  nginx:
    image: nginx:alpine
    env_file:
      - .env.prod
    ports:
      - "80:80"
      - "443:443"
    volumes:
      # 主配置模板与服务模板目录
      - ./nginx/nginx.prod.conf.template:/etc/nginx/nginx.conf.template:ro
      # 服务模板目录
      - ./nginx/conf/prod:/etc/nginx/templates:ro
      # 启动脚本（渲染模板）
      - ./nginx/entrypoint.sh:/entrypoint.sh:ro
      # SSL证书与静态文件
      - ./nginx/ssl:/etc/nginx/ssl:ro
      # 前端构建服务
      - frontend_build:/usr/share/nginx/html:ro
      # 日志目录
      - prod_nginx_logs:/var/log/nginx
    depends_on:
      oauth2_proxy:
        condition: service_healthy
      frontend_builder:
        condition: service_completed_successfully
      backend:
        condition: service_started
      portainer:
        condition: service_started
      pgadmin:
        condition: service_started
      redisinsight:
        condition: service_started
    networks:
      - prodNetWork
    # 使用动态入口脚本渲染配置
    entrypoint: ["/entrypoint.sh"]
    command: ["nginx", "-g", "daemon off;"]
    healthcheck:
      test: ["CMD", "nginx", "-t"]
      interval: 30s
      timeout: 10s
      retries: 3
    restart: unless-stopped
    mem_limit: 128M
    mem_reservation: 64M

  # 前端构建服务 - 只用于构建静态文件
  frontend_builder:
    build:
      context: ./frontend
      dockerfile: Dockerfile.prod
      args:
        - VITE_API_URL=/api
    env_file:
      - .env.prod
    volumes:
      - frontend_build:/app/dist
    networks:
      - prodNetWork

  backend:
    image: react-fastapi-postgres-backend:1.0
    build:
      context: ./backend
      dockerfile: Dockerfile.prod
    env_file:
      - .env.prod
    expose:
      - "8000"
    environment:
      - POSTGRES_HOST=${POSTGRES_HOST}
      - POSTGRES_USER=${POSTGRES_USER}
      - POSTGRES_PASSWORD=${POSTGRES_PASSWORD}
      - POSTGRES_DB=${POSTGRES_DB}
      - SECRET_KEY=${SECRET_KEY}
      - ACCESS_TOKEN_EXPIRE_MINUTES=${ACCESS_TOKEN_EXPIRE_MINUTES}
      - RABBITMQ_HOST=${RABBITMQ_HOST}
      - RABBITMQ_USER=${RABBITMQ_USER}
      - RABBITMQ_PASSWORD=${RABBITMQ_PASSWORD}
      - REDIS_HOST=${REDIS_HOST}
      - REDIS_PORT=${REDIS_PORT}
      - REDIS_DB=${REDIS_DB}
      - REDIS_PASSWORD=${REDIS_PASSWORD}
      - CHAT_BASE_URL=${CHAT_BASE_URL}
      - CHAT_API_KEY=${CHAT_API_KEY}
      - CLASSIFIER_BASE_URL=${CLASSIFIER_BASE_URL}
      - CLASSIFIER_API_KEY=${CLASSIFIER_API_KEY}
      - EMBEDDING_MODEL=${EMBEDDING_MODEL}
      - RERANKER_MODEL=${RERANKER_MODEL}
      - SPACY_MODEL_URL=${SPACY_MODEL_URL}
      - HF_HOME=/models/hf
      - HF_HUB_OFFLINE=1
    depends_on:
      postgres:
        condition: service_healthy
      rabbitmq:
        condition: service_healthy
      redis:
        condition: service_healthy
      clf_server:
        condition: service_healthy
      embeddings_init:
        condition: service_completed_successfully
      spacy_init:
        condition: service_completed_successfully
    command: >
      bash -c "
        MODEL_URL=\"$${SPACY_MODEL_URL}\" &&
        MODEL_FILE=$$(basename \"$${MODEL_URL}\") &&
        if [ -n \"$${MODEL_URL}\" ]; then \
          echo '安装本地 spaCy 模型...' && \
          echo \" - pip install /models/$${MODEL_FILE}\" && \
          pip install /models/$${MODEL_FILE} || true; \
        fi &&
        echo '等待数据库准备...' &&
        echo '应用数据库迁移...' &&
        alembic upgrade head &&
        echo '启动生产服务器...' &&
        gunicorn app.main:app -w 4 -k uvicorn.workers.UvicornWorker --bind 0.0.0.0:8000 --access-logfile - --error-logfile -
      "
    networks:
      - prodNetWork
    volumes:
      - models_data:/models:ro
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s
    restart: unless-stopped
    mem_limit: 5G
    mem_reservation: 2560M

  postgres:
    image: pgvector/pgvector:pg16
    env_file:
      - .env.prod
    expose:
      - "5432"
    environment:
      - POSTGRES_USER=${POSTGRES_USER}
      - POSTGRES_PASSWORD=${POSTGRES_PASSWORD}
      - POSTGRES_DB=${POSTGRES_DB}
    volumes:
      - prod_postgres_data:/var/lib/postgresql/data
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U ${POSTGRES_USER} -d ${POSTGRES_DB}"]
      interval: 10s
      timeout: 5s
      retries: 5
    networks:
      - prodNetWork
    restart: unless-stopped
    mem_limit: 1G
    mem_reservation: 512M

  rabbitmq:
    image: rabbitmq:4-management
    env_file:
      - .env.prod
    expose:
      - "5672"
    environment:
      - RABBITMQ_DEFAULT_USER=${RABBITMQ_USER}
      - RABBITMQ_DEFAULT_PASS=${RABBITMQ_PASSWORD}
      - RABBITMQ_DEFAULT_VHOST=${RABBITMQ_VHOST}
    volumes:
      - prod_rabbitmq_data:/var/lib/rabbitmq
    healthcheck:
      test: ["CMD", "rabbitmq-diagnostics", "ping"]
      interval: 30s
      timeout: 10s
      retries: 5
    networks:
      - prodNetWork
    restart: unless-stopped
    mem_limit: 512M
    mem_reservation: 256M

  redis:
    image: redis:7-alpine
    env_file:
      - .env.prod
    expose:
      - "6379"
    volumes:
      - prod_redis_data:/data
    command: >
      sh -c "
        redis-server --requirepass '${REDIS_PASSWORD}' --appendonly yes --maxmemory 320mb --maxmemory-policy allkeys-lru
      "
    healthcheck:
      test: ["CMD", "redis-cli", "-a", "${REDIS_PASSWORD}", "ping"]
      interval: 30s
      timeout: 5s
      retries: 5
    networks:
      - prodNetWork
    restart: unless-stopped
    mem_limit: 384M
    mem_reservation: 256M

  # 预下载模型（一次性执行，完成即退出）
  llm_init:
    image: python:3.11-slim
    env_file:
      - .env.prod
    environment:
      - HF_TOKEN=${HF_TOKEN}
      - CLASSIFIER_REPO_ID=${CLASSIFIER_REPO_ID}
      - CLASSIFIER_FILENAME=${CLASSIFIER_FILENAME}
      - CLASSIFIER_REVISION=${CLASSIFIER_REVISION:-main}
      - PIP_NO_CACHE_DIR=1
      - HF_HUB_ENABLE_HF_TRANSFER=1
    command: ["sh", "/entry-scripts/llm_init.sh"]
    volumes:
      - models_data:/models
      - ./scripts:/entry-scripts:ro
    restart: "no"
    networks:
      - prodNetWork

  # 预下载嵌入模型（一次性执行，完成即退出）
  embeddings_init:
    image: python:3.11-slim
    env_file:
      - .env.prod
    environment:
      - EMBEDDING_MODEL=${EMBEDDING_MODEL}
      - RERANKER_MODEL=${RERANKER_MODEL}
      - HF_TOKEN=${HF_TOKEN}
      - HF_HOME=/models/hf
      - HF_HUB_ENABLE_HF_TRANSFER=1
      - PIP_NO_CACHE_DIR=1
    command: ["sh", "/entry-scripts/embeddings_init.sh"]
    volumes:
      - models_data:/models
      - ./scripts:/entry-scripts:ro
    restart: "no"
    networks:
      - prodNetWork

  # 预下载 spaCy 模型（一次性执行，完成即退出）
  spacy_init:
    image: python:3.11-slim
    env_file:
      - .env.prod
    environment:
      - SPACY_MODEL_URL=${SPACY_MODEL_URL}
      - PIP_NO_CACHE_DIR=1
      - PIP_DEFAULT_TIMEOUT=1200
    command: ["sh", "/entry-scripts/spacy_init.sh"]
    volumes:
      - models_data:/models
      - ./scripts:/entry-scripts:ro
    restart: "no"
    networks:
      - prodNetWork

  clf_server:
    image: amperecomputingai/llama.cpp:3.2.1
    platform: "linux/arm64"
    env_file:
      - .env.prod
    depends_on:
      llm_init:
        condition: service_completed_successfully
    command:
      - --model
      - /models/${CLASSIFIER_FILENAME}
      - --port
      - "8080"
      - --host
      - 0.0.0.0
      - --ctx-size
      - "8192"
      - --parallel
      - "2"
      - --api-key
      - ${CLASSIFIER_API_KEY}
    expose:
      - "8080"
    healthcheck:
      test: ["CMD-SHELL", "curl -fsS http://127.0.0.1:8080/v1/models >/dev/null || exit 1"]
      interval: 15s
      timeout: 5s
      retries: 8
      start_period: 120s
    volumes:
      - models_data:/models:ro
    restart: unless-stopped
    networks:
      - prodNetWork


  taskiq_worker:
    image: react-fastapi-postgres-backend:1.0
    env_file:
      - .env.prod
    environment:
      - POSTGRES_HOST=${POSTGRES_HOST}
      - POSTGRES_USER=${POSTGRES_USER}
      - POSTGRES_PASSWORD=${POSTGRES_PASSWORD}
      - POSTGRES_DB=${POSTGRES_DB}
      - RABBITMQ_HOST=${RABBITMQ_HOST}
      - RABBITMQ_USER=${RABBITMQ_USER}
      - RABBITMQ_PASSWORD=${RABBITMQ_PASSWORD}
      - RABBITMQ_DEFAULT_VHOST=${RABBITMQ_VHOST}
      - REDIS_HOST=${REDIS_HOST}
      - REDIS_PORT=${REDIS_PORT}
      - REDIS_DB=${REDIS_DB}
      - REDIS_PASSWORD=${REDIS_PASSWORD}
      - CLASSIFIER_BASE_URL=${CLASSIFIER_BASE_URL}
      - CLASSIFIER_API_KEY=${CLASSIFIER_API_KEY}
      - HF_HOME=/models/hf
      - HF_HUB_OFFLINE=1
    depends_on:
      postgres:
        condition: service_healthy
      rabbitmq:
        condition: service_healthy
      redis:
        condition: service_healthy
      clf_server:
        condition: service_healthy
      embeddings_init:
        condition: service_completed_successfully
    command: >
      bash -c "
        echo '等待依赖服务...' &&
        sleep 15 &&
        taskiq worker --fs-discover --tasks-pattern 'app/modules/tasks/workers/*.py' app.broker:broker --log-level ${LOG_LEVEL:-WARNING}
      "
    networks:
      - prodNetWork
    volumes:
      - models_data:/models:ro
    healthcheck:
      test: ["CMD", "pgrep", "-f", "taskiq worker"]
      interval: 60s
      timeout: 10s
      retries: 3
    restart: unless-stopped
    scale: ${TASKIQ_WORKER_CONCURRENCY:-2}
    mem_limit: 3G
    mem_reservation: 1.5G

  taskiq_scheduler:
    image: react-fastapi-postgres-backend:1.0
    env_file:
      - .env.prod
    environment:
      - POSTGRES_HOST=${POSTGRES_HOST}
      - POSTGRES_USER=${POSTGRES_USER}
      - POSTGRES_PASSWORD=${POSTGRES_PASSWORD}
      - POSTGRES_DB=${POSTGRES_DB}
      - RABBITMQ_HOST=${RABBITMQ_HOST}
      - RABBITMQ_USER=${RABBITMQ_USER}
      - RABBITMQ_PASSWORD=${RABBITMQ_PASSWORD}
      - RABBITMQ_DEFAULT_VHOST=${RABBITMQ_VHOST}
      - REDIS_HOST=${REDIS_HOST}
      - REDIS_PORT=${REDIS_PORT}
      - REDIS_DB=${REDIS_DB}
      - REDIS_PASSWORD=${REDIS_PASSWORD}
      - CLASSIFIER_BASE_URL=${CLASSIFIER_BASE_URL}
      - CLASSIFIER_API_KEY=${CLASSIFIER_API_KEY}
      - HF_HOME=/models/hf
      - HF_HUB_OFFLINE=1
    depends_on:
      postgres:
        condition: service_healthy
      rabbitmq:
        condition: service_healthy
      redis:
        condition: service_healthy
      taskiq_worker:
        condition: service_started
      clf_server:
        condition: service_healthy
      embeddings_init:
        condition: service_completed_successfully
    command: >
      bash -c "
        echo '等待依赖服务...' &&
        sleep 20 &&
        taskiq scheduler app.broker:scheduler --log-level ${LOG_LEVEL:-WARNING}
      "
    networks:
      - prodNetWork
    volumes:
      - models_data:/models:ro
    healthcheck:
      test: ["CMD", "pgrep", "-f", "taskiq scheduler"]
      interval: 60s
      timeout: 10s
      retries: 3
    restart: unless-stopped
    mem_limit: 256M
    mem_reservation: 128M

  pgadmin:
    image: dpage/pgadmin4:8.8
    env_file:
      - .env.prod
    expose:
      - "80"
    environment:
      - PGADMIN_DEFAULT_EMAIL=${PGADMIN_DEFAULT_EMAIL}
      - PGADMIN_DEFAULT_PASSWORD=${PGADMIN_DEFAULT_PASSWORD}
      - PGADMIN_CONFIG_SERVER_MODE=${PGADMIN_CONFIG_SERVER_MODE}
      - PGADMIN_CONFIG_ENHANCED_COOKIE_PROTECTION=${PGADMIN_CONFIG_ENHANCED_COOKIE_PROTECTION}
      - PGADMIN_CONFIG_WTF_CSRF_ENABLED=${PGADMIN_CONFIG_WTF_CSRF_ENABLED}
    depends_on:
      postgres:
        condition: service_healthy
    networks:
      - prodNetWork
    restart: unless-stopped
    mem_limit: 256M
    mem_reservation: 128M
    healthcheck:
      test: ["CMD-SHELL", "python3 -c \"import urllib.request,sys; sys.exit(0 if urllib.request.urlopen('http://localhost/misc/ping').getcode()==200 else 1)\""]
      interval: 30s
      timeout: 10s
      retries: 3

  redisinsight:
    image: redislabs/redisinsight:2.70.0
    env_file:
      - .env.prod
    expose:
      - "5540"
    volumes:
      - prod_redisinsight_data:/db
    environment:
      - RITRUSTEDORIGINS=https://${SUBDOMAIN_REDIS}.${DOMAIN_MAIN}
    depends_on:
      redis:
        condition: service_healthy
    restart: unless-stopped
    networks:
      - prodNetWork
    mem_limit: 256M
    mem_reservation: 128M
    healthcheck:
      test: ["CMD-SHELL", "wget -q --spider http://127.0.0.1:5540/healthcheck/ || exit 1"]
      interval: 30s
      timeout: 10s
      retries: 3

  # Portainer 容器管理
  portainer:
    image: portainer/portainer-ce:2.27.9-alpine
    env_file:
      - .env.prod
    expose:
      - "9000"
    volumes:
      - /var/run/docker.sock:/var/run/docker.sock
      - prod_portainer_data:/data
    networks:
      - prodNetWork
    restart: unless-stopped
    healthcheck:
      test: ["CMD-SHELL", "wget -q --spider http://localhost:9000/api/system/status || exit 1"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s
    mem_limit: 256M
    mem_reservation: 128M

volumes:
  prod_postgres_data:
    driver: local
  prod_rabbitmq_data:
    driver: local
  prod_redis_data:
    driver: local
  prod_redisinsight_data:
    driver: local
  prod_portainer_data:
    driver: local
  prod_nginx_logs:
    driver: local
  frontend_build:
    driver: local
  models_data:
    driver: local
  

networks:
  prodNetWork:
    driver: bridge

